project_name : "Quadmesh"
experiment_name : "TEST"
description : ""

paths:
  log_dir : "training/results/quad-perso/"
  policy_saving_dir : "training/policy_saved/quad-perso/"
  wandb_model_saving_dir : "training/wandb_models/quad-perso/"
  episode_recording_dir: "training/results/quad-perso/episode_recording/"
  observation_counts_dir: "training/results/quad-perso/observation_counts/"

dataset:
  evaluation_mesh_file_path : "mesh_files/simple_quad.msh"
  training_mesh_file_path : "mesh_files/simple_quad.msh"

seed : 1

env:
  env_id : "Quadmesh-v0"
  max_episode_steps : 20
  n_darts_selected : 10
  deep : 12
  obs_size : 120
  action_restriction : false
  with_degree_observation : false
  reward_function : 0 # 0 if basics, 1 if penalize, 2 otherwise
  render_mode: null
  obs_count: true
  analysis_type : "old"

ppo:
  n_actions : 4
  n_iterations : 2
  n_episodes_per_iteration : 20
  n_epochs : 5
  batch_size: 64
  learning_rate : 0.0001
  gamma : 0.9

metrics:
  normalized_return: 0
  ep_len_mean: 0
  ep_reward_mean: 0
